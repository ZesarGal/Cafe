# -*- coding: utf-8 -*-
"""Coffee_app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zfwOkJYwEuBh9QWh5TuYcBV3mFLs5hPU
"""

# ======================================================
# Café México — Dashboard (Altair, Q1) + MAPAS (GeoPandas)
# Archivo único: cafe.py
#
# Qué incluye (todo en 1 archivo):
# - Carga CSV (no requiere upload si está Base_Cafe_Limpia.csv en el repo; si no, permite upload)
# - Filtros (segmento/estado/variable de precio/rango)
# - Tablas pandas + interpretaciones (expanders)
# - Estadísticas descriptivas (con y sin winsor) + por Estado×Segmento
# - Histogramas + boxplots (Altair) con buen espaciado
# - Correlaciones (niveles vs estandarizadas) + tabla opcional
# - PCA (biplot con etiquetas legibles) + mapas PC1/PC2 por estado (mediana)
# - Mapas editoriales estilo “Q1”:
#     (A) Mediana por estado (solo estados con datos coloreados; México en gris)
#     (AB) Figura A/B: Mediana + Cobertura(n) y rango típico P05–P95
#
# Requisitos (requirements.txt sugerido):
# streamlit==1.32.2
# pandas==2.2.2
# numpy==1.26.4
# altair==5.2.0
# scikit-learn==1.4.2
# scipy==1.13.0
# geopandas==0.14.4
# matplotlib==3.8.4
# shapely==2.0.4
#
# Archivos esperados en el repo:
# - Base_Cafe_Limpia.csv (o el nombre que pongas abajo)
# - mexico_states.geojson (con TODOS los estados; columna de nombre tipo NOM_ENT o NAME_1, etc.)
# ======================================================

import os
import numpy as np
import pandas as pd
import altair as alt
import streamlit as st

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer

# -------------------------------
# Optional: GeoPandas maps
# -------------------------------
try:
    import geopandas as gpd
    import matplotlib.pyplot as plt
    import matplotlib as mpl
except Exception:
    gpd = None
    plt = None
    mpl = None

# -------------------------------
# Page config
# -------------------------------
st.set_page_config(
    page_title="Café México — Dashboard",
    page_icon="☕",
    layout="wide",
    initial_sidebar_state="expanded",
)

# -------------------------------
# Altair theme (Q1 style)
# -------------------------------
def _q1_theme():
    return {
        "config": {
            "view": {"stroke": "transparent"},
            "axis": {
                "labelFont": "Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial",
                "titleFont": "Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial",
                "labelFontSize": 12,
                "titleFontSize": 12,
                "gridColor": "rgba(0,0,0,0.08)",
                "tickColor": "rgba(0,0,0,0.20)",
                "domainColor": "rgba(0,0,0,0.25)",
            },
            "legend": {
                "labelFont": "Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial",
                "titleFont": "Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial",
                "labelFontSize": 12,
                "titleFontSize": 12,
                "orient": "right",
                "symbolSize": 120,
            },
            "title": {
                "font": "Inter, system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial",
                "fontSize": 15,
                "anchor": "start",
            },
        }
    }

alt.themes.register("q1", _q1_theme)
alt.themes.enable("q1")
alt.data_transformers.disable_max_rows()

# -------------------------------
# CSS (spacing + cards)
# -------------------------------
st.markdown(
    """
    <style>
    .block-container {padding-top: 1.0rem; padding-bottom: 2.8rem; max-width: 1250px;}
    [data-testid="stSidebar"] {border-right: 1px solid rgba(0,0,0,0.06);}

    .hero {
      border-radius: 22px;
      padding: 22px 22px 14px 22px;
      border: 1px solid rgba(0,0,0,0.08);
      overflow: hidden;
      background: linear-gradient(120deg, rgba(20,20,20,0.92), rgba(25,75,70,0.92), rgba(60,35,25,0.92));
      background-size: 300% 300%;
      animation: gradientMove 10s ease infinite;
      box-shadow: 0 18px 45px rgba(0,0,0,0.10);
      color: white;
      margin-bottom: 0.75rem;
    }
    @keyframes gradientMove {
      0% {background-position: 0% 50%;}
      50% {background-position: 100% 50%;}
      100% {background-position: 0% 50%;}
    }
    .hero h1 {font-size: 2.0rem; margin: 0; line-height: 1.15;}
    .hero p {margin: 6px 0 0 0; color: rgba(255,255,255,0.78); font-size: 1.03rem;}
    .badge {
      display: inline-block;
      padding: 7px 10px;
      border-radius: 999px;
      background: rgba(255,255,255,0.12);
      border: 1px solid rgba(255,255,255,0.14);
      color: rgba(255,255,255,0.9);
      font-size: 0.85rem;
      margin-right: 6px;
      margin-top: 10px;
    }
    .card {
        border: 1px solid rgba(0,0,0,0.07);
        border-radius: 18px;
        padding: 14px 16px;
        background: rgba(255,255,255,0.72);
        box-shadow: 0 14px 30px rgba(0,0,0,0.05);
        margin-bottom: 1.0rem;
    }
    .muted {color: rgba(0,0,0,0.55); font-size: 0.95rem;}
    div[data-testid="stMetric"] {
        background: rgba(255,255,255,0.72);
        border: 1px solid rgba(0,0,0,0.07);
        border-radius: 16px;
        padding: 12px 16px;
        box-shadow: 0 14px 30px rgba(0,0,0,0.05);
    }
    hr {border: none; border-top: 1px solid rgba(0,0,0,0.08); margin: 1.0rem 0;}
    </style>
    """,
    unsafe_allow_html=True,
)

# ======================================================
# CONFIG: default file names
# ======================================================
DEFAULT_CSV_PATH = os.getenv("CAFE_CSV_PATH", "Base_Cafe_Limpia.csv")
DEFAULT_GEOJSON_PATH = os.getenv("CAFE_GEOJSON", "mexico_states.geojson")

# ======================================================
# Schema helpers (adapted to your base)
# ======================================================
STATE_COLS = ["Veracruz", "Puebla", "Chiapas", "Oaxaca", "Guerrero"]

PRICE_MINMAX_PAIRS = [
    ("cereza_conv", "Precio mínimo por Kilo de fruto o cereza convencional", "Precio máximo por Kilo de fruto o cereza convencional"),
    ("perg_lav_conv", "Precio mínimo por Kilo de pergamino lavado convencional", "Precio máximo por Kilo de pergamino lavado convencional"),
    ("natural_conv", "Precio mínimo por Kilo de natural convencional", "Precio máximo por Kilo de natural convencional"),
    ("verde_conv", "Precio mínimo por Kilo de verde, oro, morteado convencional", "Precio máximo por Kilo de verde, oro, morteado convencional"),
    ("perg_lav_esp", "Precio mínimo por Kilo de pergamino lavado especial", "Precio máximo por Kilo de Pergamino lavado especial"),
    ("perg_honey_esp", "Precio mínimo por Kilo de pergamino honey especial", "Precio máximo por Kilo de pergamino honey especial"),
    ("perg_semilav_esp", "Precio mínimo por Kilo de pergamino semilavado especial", "Precio máximo por Kilo de pergamino semilavado especial"),
    ("natural_esp", "Precio mínimo por Kilo de natural especial", "Precio máximo por Kilo de natural especial"),
    ("verde_esp", "Precio mínimo por Kilo de café verde, oro, morteado especial", "Precio máximo por Kilo de café verde, oro o morteado especial"),
]

SPECIAL_COLS = ["verde_esp", "natural_esp", "perg_lav_esp", "perg_honey_esp", "perg_semilav_esp"]
CONV_COLS = ["verde_conv", "natural_conv", "perg_lav_conv", "cereza_conv"]
ALL_STAGE_COLS = SPECIAL_COLS + CONV_COLS

# GeoJSON state key candidates
STATE_KEY_CANDIDATES = ["Estado", "state_name", "NAME_1", "name", "NOM_ENT"]

# Unified palette for all maps
Q1_CMAP = "viridis"

# ======================================================
# Utility functions
# ======================================================
def safe_numeric(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s, errors="coerce")

def midpoint_or_single(a, b):
    if pd.notna(a) and pd.notna(b):
        return (a + b) / 2.0
    if pd.notna(a):
        return a
    if pd.notna(b):
        return b
    return np.nan

def first_nonnull(row: pd.Series, cols: list[str]):
    for c in cols:
        v = row.get(c)
        if pd.notna(v):
            return v
    return np.nan

def derive_estado(row: pd.Series) -> str:
    # The original base seems to store state as non-empty string in exactly one of STATE_COLS
    for s in STATE_COLS:
        v = row.get(s, "")
        if isinstance(v, str) and v.strip():
            return v.strip()
    other = row.get("Otro (especifique)", "")
    if isinstance(other, str) and other.strip():
        return other.strip()
    return "No especificado"

def winsorize_series(x: pd.Series, qlo=0.01, qhi=0.99):
    x = safe_numeric(x)
    if x.notna().sum() < 10:
        return x, (np.nan, np.nan)
    lo, hi = np.nanquantile(x, [qlo, qhi])
    return x.clip(lo, hi), (float(lo), float(hi))

def _norm_state(x):
    if not isinstance(x, str):
        return str(x)
    return x.strip().lower()

@st.cache_data(show_spinner=False)
def build_variables(raw: pd.DataFrame) -> pd.DataFrame:
    df = raw.copy()

    # (A) Stage prices from midpoint(min,max)
    for key, cmin, cmax in PRICE_MINMAX_PAIRS:
        if (cmin in df.columns) or (cmax in df.columns):
            a = safe_numeric(df[cmin]) if cmin in df.columns else pd.Series([np.nan] * len(df))
            b = safe_numeric(df[cmax]) if cmax in df.columns else pd.Series([np.nan] * len(df))
            df[key] = [midpoint_or_single(x, y) for x, y in zip(a, b)]
        else:
            df[key] = np.nan

    # (B) Estado
    if any(c in df.columns for c in STATE_COLS):
        df["Estado"] = df.apply(derive_estado, axis=1)
    else:
        # fallback if already has Estado
        if "Estado" not in df.columns:
            df["Estado"] = "No especificado"

    # (C) Segmento (Especialidad vs Convencional)
    if all(c in df.columns for c in SPECIAL_COLS):
        df["I_spec"] = df[SPECIAL_COLS].notna().any(axis=1).astype(int)
    else:
        df["I_spec"] = 0
    df["Segmento"] = np.where(df["I_spec"] == 1, "Especialidad", "Convencional")

    # (D) Precio base p_i with priority: specialty -> conventional
    if all(c in df.columns for c in SPECIAL_COLS) and all(c in df.columns for c in CONV_COLS):
        df["p_i"] = df.apply(
            lambda r: first_nonnull(r, SPECIAL_COLS) if pd.notna(first_nonnull(r, SPECIAL_COLS)) else first_nonnull(r, CONV_COLS),
            axis=1,
        )
    else:
        # if not enough cols exist, try existing p_i
        if "p_i" not in df.columns:
            df["p_i"] = np.nan

    # (E) Winsorized p_iW (global cutoffs)
    df["p_iW"], cuts = winsorize_series(df["p_i"], 0.01, 0.99)
    df.attrs["winsor_lo"], df.attrs["winsor_hi"] = cuts

    return df

def describe_prices(d: pd.DataFrame, col: str) -> pd.DataFrame:
    x = safe_numeric(d[col]) if col in d.columns else pd.Series(dtype=float)
    if x.notna().sum() == 0:
        return pd.DataFrame()
    q = x.quantile([0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99])
    out = pd.DataFrame(
        {
            "n": [int(x.notna().sum())],
            "mean": [float(x.mean())],
            "std": [float(x.std(ddof=1))],
            "min": [float(x.min())],
            "p01": [float(q.loc[0.01])],
            "p05": [float(q.loc[0.05])],
            "p10": [float(q.loc[0.10])],
            "p25": [float(q.loc[0.25])],
            "p50": [float(q.loc[0.50])],
            "p75": [float(q.loc[0.75])],
            "p90": [float(q.loc[0.90])],
            "p95": [float(q.loc[0.95])],
            "p99": [float(q.loc[0.99])],
            "max": [float(x.max())],
        }
    )
    return out

def pca_2d(X: pd.DataFrame, min_nonmissing=2):
    mask = X.notna().sum(axis=1) >= min_nonmissing
    Xs = X.loc[mask].copy()
    imp = SimpleImputer(strategy="mean")
    Ximp = pd.DataFrame(imp.fit_transform(Xs), columns=Xs.columns, index=Xs.index)
    Z = StandardScaler().fit_transform(Ximp)
    pca = PCA(n_components=2)
    scores = pca.fit_transform(Z)
    loadings = pd.DataFrame(pca.components_.T, index=Xs.columns, columns=["PC1", "PC2"])
    evr = pca.explained_variance_ratio_
    return (
        pd.DataFrame(scores, index=Xs.index, columns=["PC1", "PC2"]),
        loadings,
        evr,
    )

def premium_descriptive(d: pd.DataFrame, price_col: str):
    """Descriptive premium: difference in means + semi-log % premium (if positive)."""
    if price_col not in d.columns:
        return None
    tmp = d.copy()
    tmp["_p"] = safe_numeric(tmp[price_col])
    tmp = tmp.dropna(subset=["_p", "Segmento"])
    if tmp["Segmento"].nunique() < 2:
        return None

    mu1 = tmp.loc[tmp["Segmento"] == "Especialidad", "_p"].mean()
    mu0 = tmp.loc[tmp["Segmento"] == "Convencional", "_p"].mean()
    med1 = tmp.loc[tmp["Segmento"] == "Especialidad", "_p"].median()
    med0 = tmp.loc[tmp["Segmento"] == "Convencional", "_p"].median()

    tmp_pos = tmp[tmp["_p"] > 0].copy()
    if tmp_pos["Segmento"].nunique() < 2:
        dlog = np.nan
        pct = np.nan
    else:
        mlog1 = np.log(tmp_pos.loc[tmp_pos["Segmento"] == "Especialidad", "_p"]).mean()
        mlog0 = np.log(tmp_pos.loc[tmp_pos["Segmento"] == "Convencional", "_p"]).mean()
        dlog = float(mlog1 - mlog0)
        pct = float(100.0 * (np.exp(dlog) - 1.0))

    return {
        "mu1": float(mu1),
        "mu0": float(mu0),
        "delta": float(mu1 - mu0),
        "med1": float(med1),
        "med0": float(med0),
        "dlog": dlog,
        "pct": pct,
    }

# ======================================================
# GeoPandas loading + “editorial Q1 maps”
# ======================================================
@st.cache_data(show_spinner=False)
def load_geojson_states(path: str):
    if gpd is None:
        return None, "GeoPandas no está disponible. Instala geopandas/matplotlib/shapely en requirements.txt."
    if not os.path.exists(path):
        return None, f"No encontré `{path}`. Sube un GeoJSON de estados al repo (ej. mexico_states.geojson)."
    try:
        g = gpd.read_file(path)
        return g, None
    except Exception as e:
        return None, f"No pude leer el geojson `{path}`. Error: {e}"

def _safe_state_key(gdf_states):
    key = None
    for c in STATE_KEY_CANDIDATES:
        if c in gdf_states.columns:
            key = c
            break
    return key

def _q1_map_style(ax):
    ax.set_axis_off()
    ax.set_aspect("equal", adjustable="box")

def _rep_points(gdf):
    return gdf.geometry.representative_point()

def build_state_stats_for_map(dff, price_col):
    """
    Estadísticas por estado para mapas:
      - n: # obs válidas (no-NA)
      - median: mediana
      - p05/p95: rango típico
    """
    if price_col not in dff.columns:
        return pd.DataFrame(columns=["Estado", "n", "median", "p05", "p95"])
    tmp = dff.copy()
    tmp["_p"] = safe_numeric(tmp[price_col])
    tmp = tmp.dropna(subset=["Estado", "_p"])
    if tmp.empty:
        return pd.DataFrame(columns=["Estado", "n", "median", "p05", "p95"])
    out = (
        tmp.groupby("Estado")["_p"]
        .agg(
            n="count",
            median="median",
            p05=lambda x: x.quantile(0.05),
            p95=lambda x: x.quantile(0.95),
        )
        .reset_index()
    )
    return out

def plot_map_median_only(
    g_states,
    stats_df,
    title="Base Café – Precio mediano por estado (MXN/kg)",
    value_col="median",
    label_mode="N_only",  # "N_only" or "N_and_value"
    cmap=Q1_CMAP,
    vmin=None,
    vmax=None,
):
    """
    Mapa editorial:
      - México completo en gris (contexto)
      - Sólo estados con datos coloreados
      - Etiquetas en estados con datos (N=...)
    """
    if gpd is None or plt is None or mpl is None:
        return None, "Falta geopandas/matplotlib."

    key = _safe_state_key(g_states)
    if key is None:
        return None, f"GeoJSON sin columna de estado reconocible. Columnas: {list(g_states.columns)[:25]}"

    g = g_states.copy()
    g["_k"] = g[key].astype(str).apply(_norm_state)

    s = stats_df.copy()
    s["_k"] = s["Estado"].astype(str).apply(_norm_state)

    m = g.merge(s[["_k", "n", value_col, "p05", "p95"]], on="_k", how="left")
    mm = m.dropna(subset=[value_col]).copy()

    fig, ax = plt.subplots(1, 1, figsize=(10.6, 6.3), dpi=240)
    _q1_map_style(ax)
    ax.set_title(title, loc="center", fontsize=15, pad=12)

    # Fondo: México completo
    m.plot(ax=ax, color="white", edgecolor="0.75", linewidth=0.55)

    if mm.empty:
        plt.tight_layout()
        return fig, None

    vv = mm[value_col].astype(float)
    if vmin is None:
        vmin = float(np.nanmin(vv))
    if vmax is None:
        vmax = float(np.nanmax(vv))

    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)
    cmap_obj = mpl.cm.get_cmap(cmap)

    mm.plot(
        ax=ax,
        column=value_col,
        cmap=cmap,
        edgecolor="0.55",
        linewidth=0.8,
        vmin=vmin,
        vmax=vmax,
    )

    sm = mpl.cm.ScalarMappable(norm=norm, cmap=cmap_obj)
    sm._A = []
    cbar = fig.colorbar(sm, ax=ax, fraction=0.028, pad=0.02)
    cbar.set_label("Precio mediano (MXN/kg)", fontsize=11)

    reps = _rep_points(mm)
    for (x, y, st_name, nval, med) in zip(reps.x, reps.y, mm[key].astype(str), mm["n"], mm[value_col]):
        if label_mode == "N_and_value":
            lab = f"{st_name}\nN={int(nval)}\n{med:,.0f}"
        else:
            lab = f"{st_name}\nN={int(nval)}"
        ax.text(
            x, y, lab,
            ha="center", va="center",
            fontsize=9,
            bbox=dict(boxstyle="round,pad=0.22", fc="white", ec="0.80", alpha=0.92),
        )

    plt.tight_layout()
    return fig, None

def plot_figure_AB_median_and_coverage(
    g_states,
    stats_df,
    titleA="A  Base Café – Precio mediano por estado (MXN/kg)",
    titleB="B  Base Café – Registros y rango típico de precios por estado (MXN/kg)",
    cmapA=Q1_CMAP,
    cmapB=Q1_CMAP,
):
    """
    Figura AB:
      A: Mediana (colorea estados con datos + etiquetas N)
      B: Cobertura (n) como color + etiquetas N y rango típico P05–P95
    """
    if gpd is None or plt is None or mpl is None:
        return None, "Falta geopandas/matplotlib."

    key = _safe_state_key(g_states)
    if key is None:
        return None, f"GeoJSON sin columna de estado reconocible. Columnas: {list(g_states.columns)[:25]}"

    g = g_states.copy()
    g["_k"] = g[key].astype(str).apply(_norm_state)

    s = stats_df.copy()
    s["_k"] = s["Estado"].astype(str).apply(_norm_state)

    m = g.merge(s[["_k", "n", "median", "p05", "p95"]], on="_k", how="left")
    mm = m.dropna(subset=["median"]).copy()

    fig, axes = plt.subplots(1, 2, figsize=(16.8, 7.2), dpi=240)
    axA, axB = axes

    for ax in axes:
        _q1_map_style(ax)

    # Panel A
    axA.set_title(titleA, loc="center", fontsize=14, pad=10)
    m.plot(ax=axA, color="white", edgecolor="0.75", linewidth=0.55)

    if not mm.empty:
        vminA, vmaxA = float(np.nanmin(mm["median"])), float(np.nanmax(mm["median"]))
        mm.plot(
            ax=axA,
            column="median",
            cmap=cmapA,
            edgecolor="0.55",
            linewidth=0.8,
            vmin=vminA,
            vmax=vmaxA,
        )
        smA = mpl.cm.ScalarMappable(norm=mpl.colors.Normalize(vminA, vmaxA), cmap=mpl.cm.get_cmap(cmapA))
        smA._A = []
        cbarA = fig.colorbar(smA, ax=axA, fraction=0.028, pad=0.02)
        cbarA.set_label("Precio mediano (MXN/kg)", fontsize=10)

        repsA = _rep_points(mm)
        for x, y, st_name, nval in zip(repsA.x, repsA.y, mm[key].astype(str), mm["n"]):
            axA.text(
                x, y, f"{st_name}\nN={int(nval)}",
                ha="center", va="center",
                fontsize=8.8,
                bbox=dict(boxstyle="round,pad=0.22", fc="white", ec="0.80", alpha=0.92),
            )

    # Panel B
    axB.set_title(titleB, loc="center", fontsize=14, pad=10)
    m.plot(ax=axB, color="white", edgecolor="0.75", linewidth=0.55)

    if not mm.empty:
        vminB, vmaxB = float(np.nanmin(mm["n"])), float(np.nanmax(mm["n"]))
        mm.plot(
            ax=axB,
            column="n",
            cmap=cmapB,
            edgecolor="0.55",
            linewidth=0.8,
            vmin=vminB,
            vmax=vmaxB,
        )
        smB = mpl.cm.ScalarMappable(norm=mpl.colors.Normalize(vminB, vmaxB), cmap=mpl.cm.get_cmap(cmapB))
        smB._A = []
        cbarB = fig.colorbar(smB, ax=axB, fraction=0.028, pad=0.02)
        cbarB.set_label("Número de registros", fontsize=10)

        repsB = _rep_points(mm)
        for x, y, st_name, nval, p05, p95 in zip(repsB.x, repsB.y, mm[key].astype(str), mm["n"], mm["p05"], mm["p95"]):
            axB.text(
                x, y,
                f"{st_name}\nN={int(nval)}\nTípico: {p05:,.0f}–{p95:,.0f}",
                ha="center", va="center",
                fontsize=8.2,
                bbox=dict(boxstyle="round,pad=0.24", fc="white", ec="0.80", alpha=0.92),
            )

        axB.text(
            0.02, 0.02,
            "Rango típico = P05 a P95.\nExtremos pueden incluir outliers o capturas atípicas.",
            transform=axB.transAxes,
            fontsize=8.4,
            color="0.35",
            va="bottom",
        )

    plt.tight_layout()
    return fig, None

def make_state_map_centered(gdf_states, stats_df, stats_col: str, title: str, center_zero: bool = True, cmap=Q1_CMAP):
    """
    Choropleth centrado en 0 (para PC1/PC2 por estado).
    México en gris; sólo estados con datos coloreados.
    """
    if gpd is None or plt is None or mpl is None:
        return None, "GeoPandas/Matplotlib no disponibles."

    key = _safe_state_key(gdf_states)
    if key is None:
        return None, f"GeoJSON sin columna de estado reconocible. Columnas: {list(gdf_states.columns)[:25]}"

    g = gdf_states.copy()
    g["_k"] = g[key].astype(str).apply(_norm_state)

    s = stats_df.copy()
    s["_k"] = s["Estado"].astype(str).apply(_norm_state)

    m = g.merge(s[["_k", stats_col]], on="_k", how="left")
    mm = m.dropna(subset=[stats_col]).copy()

    fig, ax = plt.subplots(1, 1, figsize=(10.6, 6.3), dpi=240)
    _q1_map_style(ax)
    ax.set_title(title, loc="center", fontsize=14, pad=10)

    m.plot(ax=ax, color="white", edgecolor="0.75", linewidth=0.55)

    if mm.empty:
        plt.tight_layout()
        return fig, None

    vv = mm[stats_col].astype(float)
    if center_zero:
        vmax = float(np.nanmax(np.abs(vv)))
        vmin = -vmax
    else:
        vmin = float(np.nanmin(vv))
        vmax = float(np.nanmax(vv))

    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)
    cmap_obj = mpl.cm.get_cmap("RdBu_r" if center_zero else cmap)

    mm.plot(
        ax=ax,
        column=stats_col,
        cmap=("RdBu_r" if center_zero else cmap),
        edgecolor="0.55",
        linewidth=0.8,
        vmin=vmin,
        vmax=vmax,
    )

    sm = mpl.cm.ScalarMappable(norm=norm, cmap=cmap_obj)
    sm._A = []
    cbar = fig.colorbar(sm, ax=ax, fraction=0.028, pad=0.02)
    cbar.set_label(stats_col, fontsize=10)

    plt.tight_layout()
    return fig, None

# ======================================================
# Header
# ======================================================
st.markdown(
    """
    <div class="hero">
      <h1>☕ Café México — Dashboard</h1>
      <p>Precios (con y sin winsor), heterogeneidad territorial, correlaciones y PCA.</p>
      <span class="badge"></span>
      <span class="badge">Filtros</span>
      <span class="badge">Tablas</span>
      <span class="badge">Hist & Box</span>
      <span class="badge">Correlaciones</span>
      <span class="badge">PCA</span>
      <span class="badge">GeoPandas maps</span>
    </div>
    """,
    unsafe_allow_html=True,
)

# ======================================================
# Definición de prima (caja desplegable)
# ======================================================
with st.expander("Definición matemática de prima (clic para desplegar)", expanded=False):
    st.markdown(r"""
En este proyecto, una **prima (premium)** es una diferencia sistemática de precios asociada al segmento
(**especialidad** vs **convencional**).

Sea \(p_i>0\) el precio (MXN/kg) observado para la unidad \(i\). Sea \(D_i\in\{0,1\}\) un indicador de especialidad
(\(D_i=1\) especialidad, \(D_i=0\) convencional).

### Prima en niveles
\[
\Delta \;=\; \mathbb{E}[p_i \mid D_i=1] \;-\; \mathbb{E}[p_i \mid D_i=0].
\]

### Prima porcentual (semi-log)
\[
y_i=\log(p_i),\qquad
\Delta_{\log} \;=\; \mathbb{E}[y_i \mid D_i=1]-\mathbb{E}[y_i \mid D_i=0],
\qquad
\%\text{prima}\approx 100\,(e^{\Delta_{\log}}-1).
\]

### Prima condicional por territorio (idea)
\[
\log(p_i)=\alpha+\beta D_i+\gamma_{s(i)}+u_i,
\]
donde \(\gamma_{s(i)}\) son efectos fijos por estado. Aquí \(\beta\) es una prima “dentro de territorio”.
""")

# ======================================================
# Load data: prefer repo CSV; else allow upload
# ======================================================
st.sidebar.markdown("## 1) Base de datos (CSV)")
use_repo = st.sidebar.toggle("Usar CSV del repo (sin subir archivo)", value=True)

raw = None
if use_repo and os.path.exists(DEFAULT_CSV_PATH):
    try:
        raw = pd.read_csv(DEFAULT_CSV_PATH)
        st.sidebar.success(f"Usando: {DEFAULT_CSV_PATH}")
    except Exception as e:
        st.sidebar.error(f"No pude leer {DEFAULT_CSV_PATH}: {e}")
        raw = None

if raw is None:
    uploaded = st.sidebar.file_uploader("Sube tu CSV", type=["csv"])
    if uploaded is None:
        st.info("Sube un CSV o coloca el archivo en el repo con el nombre Base_Cafe_Limpia.csv.")
        st.stop()
    try:
        raw = pd.read_csv(uploaded)
    except Exception as e:
        st.error(f"No pude leer el CSV. Error: {e}")
        st.stop()

df = build_variables(raw)

# ======================================================
# Sidebar filters
# ======================================================
st.sidebar.markdown("---")
st.sidebar.markdown("## 2) Filtros")

seg = st.sidebar.radio("Segmento", ["Todos", "Especialidad", "Convencional"], index=0)

states = sorted(df["Estado"].dropna().unique().tolist())
default_states = [s for s in ["Chiapas", "Oaxaca", "Veracruz", "Puebla", "Guerrero"] if s in states]
sel_states = st.sidebar.multiselect("Estado", states, default=default_states or states[:5])

price_mode = st.sidebar.selectbox(
    "Variable de precio",
    ["Precio base (p_i)", "Precio base winsorizado (p_iW)"] + [f"Etapa: {c}" for c in ALL_STAGE_COLS],
    index=1,
)
if price_mode.startswith("Etapa: "):
    price_col = price_mode.replace("Etapa: ", "")
else:
    price_col = "p_iW" if "winsorizado" in price_mode else "p_i"

use_log = st.sidebar.toggle("Escala log en ejes de precio", value=False)
show_points = st.sidebar.toggle("Mostrar puntos (jitter) en boxplots", value=False)

px_series = safe_numeric(df[price_col]) if price_col in df.columns else pd.Series([np.nan] * len(df))
if px_series.notna().any():
    minp, maxp = float(np.nanmin(px_series)), float(np.nanmax(px_series))
    pr_range = st.sidebar.slider("Rango de precio (MXN/kg)", min_value=minp, max_value=maxp, value=(minp, maxp))
else:
    pr_range = None

st.sidebar.markdown("---")
st.sidebar.download_button(
    "⬇️ Descargar CSV (con variables derivadas)",
    data=df.to_csv(index=False).encode("utf-8"),
    file_name="base_cafe_con_variables.csv",
    mime="text/csv",
)

# Apply filters
dff = df.copy()
dff = dff[dff["Estado"].isin(sel_states)]
if seg != "Todos":
    dff = dff[dff["Segmento"] == seg]
if pr_range is not None and price_col in dff.columns:
    s_ = safe_numeric(dff[price_col])
    dff = dff[(s_.isna()) | ((s_ >= pr_range[0]) & (s_ <= pr_range[1]))]

# KPIs
lo, hi = df.attrs.get("winsor_lo", np.nan), df.attrs.get("winsor_hi", np.nan)
s_sel = safe_numeric(dff[price_col]) if price_col in dff.columns else pd.Series(dtype=float)

k1, k2, k3, k4 = st.columns(4)
with k1:
    st.metric("Observaciones (filtradas)", f"{len(dff):,}")
with k2:
    st.metric("Mediana", f"{np.nanmedian(s_sel):,.2f} MXN/kg" if s_sel.notna().any() else "—")
with k3:
    st.metric("P10–P90", f"{np.nanquantile(s_sel,0.10):,.1f}–{np.nanquantile(s_sel,0.90):,.1f}" if s_sel.notna().sum() >= 5 else "—")
with k4:
    st.metric("Winsor global (para p_i)", f"{lo:,.2f} / {hi:,.2f}" if np.isfinite(lo) and np.isfinite(hi) else "—")

# ======================================================
# Tabs
# ======================================================
st.markdown("---")
tab0, tab1, tab2, tab3, tab4, tab5 = st.tabs(
    ["Resumen + Mapas", "Descriptivas", "Distribuciones", "Boxplots", "Correlaciones", "PCA + Mapas"]
)

# ======================================================
# TAB 0 — Summary + Editorial maps like your example
# ======================================================
with tab0:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("### Vista rápida (tabla)")
    st.markdown(
        '<div class="muted">Tabla filtrada (primeras 300 filas) para revisar consistencia, faltantes y codificación territorial.</div>',
        unsafe_allow_html=True,
    )
    st.dataframe(dff.head(300), use_container_width=True, height=460)
    st.markdown("</div>", unsafe_allow_html=True)

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("### Mapas editoriales por estado (como tu figura)")

    if gpd is None or plt is None or mpl is None:
        st.warning("Para mapas necesitas geopandas + matplotlib + shapely en requirements.txt.")
    else:
        geo_path = st.text_input("Ruta GeoJSON estados", value=DEFAULT_GEOJSON_PATH, key="geo_tab0")
        g_states, g_err = load_geojson_states(geo_path)

        if g_err:
            st.warning(g_err)
            st.info("Tip: sube mexico_states.geojson al repo y verifica que tenga todos los estados.")
        else:
            stats_state = build_state_stats_for_map(dff, price_col)

            if stats_state.empty:
                st.info("No hay datos suficientes para construir el mapa con los filtros actuales.")
            else:
                # A: map median
                figA, eA = plot_map_median_only(
                    g_states,
                    stats_state,
                    title="Base Café – Precio mediano por estado (MXN/kg)",
                    value_col="median",
                    label_mode="N_only",
                    cmap=Q1_CMAP,
                )
                if eA:
                    st.warning(eA)
                else:
                    st.pyplot(figA, use_container_width=True)

                # AB: A/B figure
                st.markdown("#### Figura AB (mediana y cobertura + rango típico)")
                figAB, eAB = plot_figure_AB_median_and_coverage(
                    g_states,
                    stats_state,
                    titleA="A  Base Café – Precio mediano por estado (MXN/kg)",
                    titleB="B  Base Café – Registros y rango típico de precios por estado (MXN/kg)",
                    cmapA=Q1_CMAP,
                    cmapB=Q1_CMAP,
                )
                if eAB:
                    st.warning(eAB)
                else:
                    st.pyplot(figAB, use_container_width=True)

                with st.expander("Interpretación (texto sugerido para el capítulo)", expanded=True):
                    st.markdown(
                        "- **Panel A (mediana)**: compara niveles típicos por estado sin estar dominado por valores extremos.\n"
                        "- **Panel B (cobertura y rango típico)**: el color representa **n**; el recuadro muestra **P05–P95**, "
                        "un resumen robusto de dispersión evitando outliers.\n"
                        "- Estos mapas son **descriptivos**: fijan el terreno para modelos con efectos fijos y para una lectura territorial del PCA."
                    )

                with st.expander("Tabla (agregados por estado)", expanded=False):
                    st.dataframe(
                        stats_state.sort_values("n", ascending=False)
                        .style.format({"median": "{:,.2f}", "p05": "{:,.2f}", "p95": "{:,.2f}", "n": "{:d}"}),
                        use_container_width=True,
                        height=330,
                    )

    st.markdown("</div>", unsafe_allow_html=True)

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("### Prima descriptiva (rápida) para la variable seleccionada")
    prem = premium_descriptive(dff, price_col) if (price_col in dff.columns) else None
    if prem is None:
        st.info("Se requieren ambos segmentos (Especialidad y Convencional) y datos válidos de precio para estimar una prima descriptiva.")
    else:
        c1, c2, c3 = st.columns(3)
        with c1:
            st.metric("Δ (media): Especialidad − Convencional", f"{prem['delta']:,.2f} MXN/kg")
        with c2:
            st.metric("Prima % (semi-log aprox.)", f"{prem['pct']:,.1f}%" if np.isfinite(prem["pct"]) else "—")
        with c3:
            st.metric("Δlog (media log)", f"{prem['dlog']:.3f}" if np.isfinite(prem["dlog"]) else "—")

        with st.expander("Interpretación", expanded=True):
            st.markdown(
                "- **Δ en niveles**: diferencia promedio en MXN/kg.\n"
                "- **Δlog**: diferencia en log-precios (semi-elasticidad).\n"
                "- **%prima**: \(100(\exp(\\Delta_{\\log})-1)\) aproxima el diferencial porcentual entre segmentos."
            )
    st.markdown("</div>", unsafe_allow_html=True)

# ======================================================
# TAB 1 — Descriptives
# ======================================================
with tab1:
    left, right = st.columns(2, gap="large")

    with left:
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("### Estadísticas descriptivas — \(p_i\) (original)")
        desc_pi = describe_prices(dff, "p_i")
        if desc_pi.empty:
            st.info("No hay datos en p_i con los filtros actuales.")
        else:
            st.dataframe(desc_pi.style.format("{:,.2f}"), use_container_width=True)
        with st.expander("Interpretación", expanded=True):
            st.markdown(
                "- **Cuantiles (p01, p05, …)**: describen colas y asimetrías.\n"
                "- Si p99 o max es muy grande respecto a p95, hay evidencia de valores extremos.\n"
                "- Esto motiva winsorización (recorte suave) para robustez."
            )
        st.markdown("</div>", unsafe_allow_html=True)

    with right:
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("### Estadísticas descriptivas — \(p_i^W\) (winsorizado)")
        desc_piW = describe_prices(dff, "p_iW")
        if desc_piW.empty:
            st.info("No hay datos en p_iW con los filtros actuales.")
        else:
            st.dataframe(desc_piW.style.format("{:,.2f}"), use_container_width=True)
        with st.expander("Interpretación", expanded=True):
            st.markdown(
                "- \(p_i^W\\) limita el impacto de outliers (por ejemplo, P01–P99 global).\n"
                "- La media y desviación estándar suelen estabilizarse.\n"
                "- Para comparar territorios/segmentos, \(p_i^W\\) reduce sensibilidad a capturas atípicas."
            )
        st.markdown("</div>", unsafe_allow_html=True)

    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown(f"### Descriptivas por Estado × Segmento — {price_col}")
    if price_col not in dff.columns:
        st.warning("La variable seleccionada no existe en la base.")
    else:
        tmp = dff.copy()
        tmp["_price"] = safe_numeric(tmp[price_col])
        g = (
            tmp.dropna(subset=["_price"])
            .groupby(["Estado", "Segmento"])["_price"]
            .agg(
                n="count",
                mean="mean",
                median="median",
                std="std",
                p10=lambda x: x.quantile(0.10),
                p90=lambda x: x.quantile(0.90),
            )
            .reset_index()
            .sort_values(["Estado", "Segmento"])
        )
        st.dataframe(
            g.style.format({"mean": "{:,.2f}", "median": "{:,.2f}", "std": "{:,.2f}", "p10": "{:,.2f}", "p90": "{:,.2f}"}),
            use_container_width=True,
            height=560,
        )
        with st.expander("Interpretación", expanded=True):
            st.markdown(
                "- **Heterogeneidad territorial**: diferencias en medianas sugieren variación sistemática entre estados.\n"
                "- **Heterogeneidad por segmento**: comparar Especialidad vs Convencional dentro del mismo estado.\n"
                "- **p10–p90**: rango interdecílico; útil para dispersión sin colas extremas."
            )
    st.markdown("</div>", unsafe_allow_html=True)

# ======================================================
# TAB 2 — Histograms
# ======================================================
with tab2:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown(f"### Histograma interactivo — {price_col}")

    if price_col not in dff.columns:
        st.warning("La variable seleccionada no existe.")
    else:
        tmp = dff.dropna(subset=[price_col]).copy()
        tmp["_price"] = safe_numeric(tmp[price_col])

        if tmp.empty:
            st.info("No hay datos para graficar con los filtros actuales.")
        else:
            if use_log:
                tmp = tmp[tmp["_price"] > 0].copy()
                tmp["_x"] = np.log(tmp["_price"])
                x_enc = alt.X("_x:Q", bin=alt.Bin(maxbins=40), title="log(Precio)")
            else:
                tmp["_x"] = tmp["_price"]
                x_enc = alt.X("_x:Q", bin=alt.Bin(maxbins=40), title="Precio (MXN/kg)")

            hist = (
                alt.Chart(tmp)
                .mark_bar(opacity=0.85)
                .encode(
                    x=x_enc,
                    y=alt.Y("count():Q", title="Frecuencia"),
                    color=alt.Color("Segmento:N", title="Segmento"),
                    tooltip=[alt.Tooltip("count():Q", title="n")],
                )
                .properties(height=440)
            )
            st.altair_chart(hist.interactive(), use_container_width=True)

            with st.expander("Interpretación", expanded=True):
                st.markdown(
                    "- Si la distribución tiene cola derecha larga, el eje log ayuda a visualizar estructura interna.\n"
                    "- Diferencias por color (segmento) sugieren primas/discriminación de mercado.\n"
                    "- Multimodalidad puede reflejar mezcla de etapas/procesos (lavado vs honey vs natural) o territorios."
                )

    st.markdown("</div>", unsafe_allow_html=True)

# ======================================================
# TAB 3 — Boxplots
# ======================================================
with tab3:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown(f"### Boxplot por Estado — {price_col}")

    if price_col not in dff.columns:
        st.warning("La variable seleccionada no existe.")
    else:
        tmp = dff.copy()
        tmp["_price"] = safe_numeric(tmp[price_col])
        tmp = tmp.dropna(subset=["_price"])

        if tmp.empty:
            st.info("No hay datos para boxplot con los filtros actuales.")
        else:
            order = tmp.groupby("Estado")["_price"].median().sort_values().index.tolist()

            if use_log:
                tmp = tmp[tmp["_price"] > 0].copy()
                tmp["_y"] = np.log(tmp["_price"])
                y_enc = alt.Y("_y:Q", title="log(Precio)")
                tooltip_price = alt.Tooltip("_price:Q", format=",.2f", title="Precio (MXN/kg)")
            else:
                tmp["_y"] = tmp["_price"]
                y_enc = alt.Y("_y:Q", title="Precio (MXN/kg)")
                tooltip_price = alt.Tooltip("_price:Q", format=",.2f", title="Precio (MXN/kg)")

            base = alt.Chart(tmp).encode(
                x=alt.X("Estado:N", sort=order, title="Estado"),
                y=y_enc,
                color=alt.Color("Segmento:N", title="Segmento"),
                tooltip=[alt.Tooltip("Estado:N"), alt.Tooltip("Segmento:N"), tooltip_price],
            )

            box = base.mark_boxplot(size=28, opacity=0.85).properties(height=560)
            chart = box

            if show_points:
                pts = base.mark_circle(size=18, opacity=0.18).properties(height=560)
                chart = box + pts

            st.altair_chart(chart.interactive(), use_container_width=True)

            with st.expander("Interpretación", expanded=True):
                st.markdown(
                    "- La **línea central** es la mediana; la **caja** es IQR (p25–p75).\n"
                    "- Cajas más altas: mayor dispersión típica.\n"
                    "- Comparar colores dentro del estado ayuda a ver prima territorial.\n"
                    "- Outliers: puntos fuera del rango; winsorización ayuda a robustez en modelos."
                )

    st.markdown("</div>", unsafe_allow_html=True)

# ======================================================
# TAB 4 — Correlations (heatmaps)
# ======================================================
with tab4:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("### Correlaciones entre etapas/precios (heatmaps)")

    have_cols = [c for c in ALL_STAGE_COLS if c in dff.columns]
    if len(have_cols) < 3:
        st.warning("No hay suficientes columnas de etapa para correlaciones (se requieren al menos 3).")
    else:
        X = dff[have_cols].copy()
        corr_raw = X.corr(min_periods=15)

        Z = (X - X.mean()) / X.std(ddof=1)
        corr_std = Z.corr(min_periods=15)

        def corr_long(C: pd.DataFrame, label: str) -> pd.DataFrame:
            L = C.stack(dropna=False).reset_index()
            L.columns = ["var1", "var2", "corr"]
            L["tipo"] = label
            return L

        L = pd.concat([corr_long(corr_raw, "Niveles"), corr_long(corr_std, "Estandarizadas")], ignore_index=True)
        L["var1"] = pd.Categorical(L["var1"], categories=have_cols, ordered=True)
        L["var2"] = pd.Categorical(L["var2"], categories=have_cols, ordered=True)

        heat = (
            alt.Chart(L)
            .mark_rect()
            .encode(
                x=alt.X("var2:N", title="", sort=have_cols, axis=alt.Axis(labelAngle=-35)),
                y=alt.Y("var1:N", title="", sort=have_cols),
                color=alt.Color("corr:Q", title="Corr", scale=alt.Scale(domain=[-1, 1], scheme="redblue")),
                tooltip=[alt.Tooltip("var1:N"), alt.Tooltip("var2:N"), alt.Tooltip("corr:Q", format=".2f")],
            )
            .properties(height=420)
        )

        text = alt.Chart(L).mark_text(fontSize=10).encode(
            x="var2:N",
            y="var1:N",
            text=alt.Text("corr:Q", format=".2f"),
            color=alt.condition("abs(datum.corr) > 0.65", alt.value("black"), alt.value("rgba(0,0,0,0.55)")),
        )

        charts = (heat + text).facet(column=alt.Column("tipo:N", title=""))
        st.altair_chart(charts, use_container_width=True)

        with st.expander("Interpretación", expanded=True):
            st.markdown(
                "- **Niveles**: correlación directa en MXN/kg; refleja escala y mezcla de estados/procesos.\n"
                "- **Estandarizadas**: controla escala variable; resalta co-movimientos relativos.\n"
                "- Cambios entre paneles sugieren que parte de la correlación venía de diferencias de escala (no de estructura conjunta)."
            )

        show_table = st.toggle("Mostrar tabla de correlación (niveles)", value=False)
        if show_table:
            st.dataframe(corr_raw.style.format("{:.2f}"), use_container_width=True, height=420)

    st.markdown("</div>", unsafe_allow_html=True)

# ======================================================
# TAB 5 — PCA + Maps (PC1/PC2 by state)
# ======================================================
with tab5:
    st.markdown('<div class="card">', unsafe_allow_html=True)
    st.markdown("### PCA (biplot) con precios estandarizados + mapas PC1/PC2 por estado")

    block = st.radio("Bloque PCA", ["Especialidad", "Convencional", "Todo (etapas)"], horizontal=True)

    if block == "Especialidad":
        cols = [c for c in SPECIAL_COLS if c in dff.columns]
        min_nonmissing = 2
        title = "PCA — Especialidad"
    elif block == "Convencional":
        cols = [c for c in CONV_COLS if c in dff.columns]
        min_nonmissing = 2
        title = "PCA — Convencional"
    else:
        cols = [c for c in ALL_STAGE_COLS if c in dff.columns]
        min_nonmissing = 3
        title = "PCA — Todo (etapas)"

    if len(cols) < min_nonmissing:
        st.warning("No hay suficientes columnas para correr el PCA con este bloque.")
        st.markdown("</div>", unsafe_allow_html=True)
    else:
        scores, loadings, evr = pca_2d(dff[cols], min_nonmissing=min_nonmissing)
        s = scores.copy()
        s["Segmento"] = dff.loc[s.index, "Segmento"].values
        s["Estado"] = dff.loc[s.index, "Estado"].values

        ev = pd.DataFrame({"Componente": ["PC1", "PC2"], "Varianza (%)": [evr[0] * 100, evr[1] * 100]})
        ev_ch = (
            alt.Chart(ev)
            .mark_bar()
            .encode(
                x=alt.X("Componente:N", title=""),
                y=alt.Y("Varianza (%):Q", title="Varianza explicada (%)"),
                tooltip=[alt.Tooltip("Varianza (%):Q", format=".2f")],
            )
            .properties(height=220, title="Varianza explicada (PC1–PC2)")
        )
        st.altair_chart(ev_ch, use_container_width=True)

        # Biplot (Altair) with readable labels
        sel = alt.selection_point(fields=["Segmento"], bind="legend")

        pts = (
            alt.Chart(s.reset_index(drop=True))
            .mark_circle(size=60, opacity=0.55)
            .encode(
                x=alt.X("PC1:Q", title="PC1"),
                y=alt.Y("PC2:Q", title="PC2"),
                color=alt.Color("Segmento:N", title="Segmento"),
                tooltip=[
                    alt.Tooltip("PC1:Q", format=".2f"),
                    alt.Tooltip("PC2:Q", format=".2f"),
                    alt.Tooltip("Estado:N"),
                    alt.Tooltip("Segmento:N"),
                ],
            )
            .add_params(sel)
            .transform_filter(sel)
            .properties(height=520, title=title)
        )

        # Loadings arrows
        scale = 3.0
        Ld = loadings.copy()
        Ld["x"] = 0.0
        Ld["y"] = 0.0
        Ld["x2"] = Ld["PC1"] * scale
        Ld["y2"] = Ld["PC2"] * scale
        Ld["var"] = Ld.index

        segs = alt.Chart(Ld.reset_index(drop=True)).mark_rule(opacity=0.95, strokeWidth=2.5).encode(
            x="x:Q",
            y="y:Q",
            x2="x2:Q",
            y2="y2:Q",
            tooltip=[alt.Tooltip("var:N"), alt.Tooltip("PC1:Q", format=".2f"), alt.Tooltip("PC2:Q", format=".2f")],
        )
        labels = alt.Chart(Ld.reset_index(drop=True)).mark_text(align="left", dx=6, dy=-6, fontSize=11).encode(
            x="x2:Q", y="y2:Q", text="var:N"
        )

        st.altair_chart((pts + segs + labels).interactive(), use_container_width=True)

        with st.expander("Interpretación del biplot", expanded=True):
            st.markdown(
                "- Los **puntos** son observaciones (precios estandarizados) proyectadas en PC1–PC2.\n"
                "- Las **flechas** indican variables que “empujan” en cada dirección (cargas).\n"
                "- Si dos flechas apuntan similar, esas variables tienden a co-mover.\n"
                "- Estados/segmentos que caen hacia la dirección de una flecha tienden a tener valores relativamente altos en esa variable."
            )

        st.markdown("</div>", unsafe_allow_html=True)

        # Maps of PC1/PC2 by state (median score)
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown("### Mapas PCA por estado: mediana(PC1) y mediana(PC2)")

        if gpd is None or plt is None or mpl is None:
            st.warning("Para mapas necesitas geopandas + matplotlib + shapely.")
        else:
            geo_path = st.text_input("Ruta GeoJSON estados (para PCA)", value=DEFAULT_GEOJSON_PATH, key="geo_tab5")
            g_states, g_err = load_geojson_states(geo_path)

            if g_err:
                st.warning(g_err)
            else:
                med = (
                    s.groupby("Estado")[["PC1", "PC2"]]
                    .median()
                    .reset_index()
                    .rename(columns={"PC1": "PC1_mediana", "PC2": "PC2_mediana"})
                )
                n_by = s.groupby("Estado")["PC1"].size().reset_index(name="n_obs")
                med = med.merge(n_by, on="Estado", how="left")

                c1, c2 = st.columns(2, gap="large")

                with c1:
                    fig1, e1 = make_state_map_centered(
                        g_states,
                        med.rename(columns={"PC1_mediana": "PC1_mediana"}),
                        "PC1_mediana",
                        "PC1 (mediana del score por estado)",
                        center_zero=True,
                    )
                    if e1:
                        st.warning(e1)
                    else:
                        st.pyplot(fig1, use_container_width=True)

                with c2:
                    fig2, e2 = make_state_map_centered(
                        g_states,
                        med.rename(columns={"PC2_mediana": "PC2_mediana"}),
                        "PC2_mediana",
                        "PC2 (mediana del score por estado)",
                        center_zero=True,
                    )
                    if e2:
                        st.warning(e2)
                    else:
                        st.pyplot(fig2, use_container_width=True)

                with st.expander("Interpretación (PC1/PC2 territorial)", expanded=True):
                    st.markdown(
                        "- **PC1 territorial**: dimensión dominante de variación (combinación lineal de precios estandarizados).\n"
                        "- **PC2 territorial**: contraste ortogonal a PC1; suele capturar diferencias de proceso/etapa.\n"
                        "- Mapear medianas por estado ayuda a leer patrones de organización/mercado a escala territorial.\n"
                        "- Considera siempre **n_obs**: con pocos datos la mediana del score es menos estable."
                    )

                with st.expander("Tabla por estado (PC1/PC2 medianas + n_obs)", expanded=False):
                    st.dataframe(
                        med.sort_values("n_obs", ascending=False)
                        .style.format({"PC1_mediana": "{:.3f}", "PC2_mediana": "{:.3f}", "n_obs": "{:d}"}),
                        use_container_width=True,
                        height=360,
                    )

        st.markdown("</div>", unsafe_allow_html=True)